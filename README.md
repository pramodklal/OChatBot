# ğŸ¤– Multi-Files Chatbot using OpenAI - RAG System

A powerful Retrieval-Augmented Generation (RAG) chatbot built with Streamlit that allows users to upload multiple document formats (PDF, DOCX, TXT) and ask questions based on the content using OpenAI's GPT models.

![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)
![LangChain](https://img.shields.io/badge/LangChain-Latest-green.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-orange.svg)

---

## ğŸ“‹ Solution Brief

This application implements a sophisticated RAG (Retrieval-Augmented Generation) system that enables users to:

- **Upload Multiple Document Types**: Support for PDF, DOCX, and TXT files
- **Intelligent Document Processing**: Automatic text extraction and chunking
- **Semantic Search**: FAISS-powered vector similarity search
- **AI-Powered Responses**: Multiple OpenAI GPT model options (GPT-4, GPT-4-Turbo, GPT-3.5-Turbo)
- **Conversational Interface**: Streamlit-based chat UI with message history
- **Error Handling**: Rate limiting protection with exponential backoff

### Key Features

âœ… **Multi-format Document Support** - PDF, DOCX, TXT  
âœ… **Multiple AI Models** - Choose from GPT-4, GPT-4-Turbo, or GPT-3.5-Turbo  
âœ… **Vector Similarity Search** - FAISS for efficient document retrieval  
âœ… **Conversational Interface** - Chat-style interaction with history  
âœ… **Rate Limit Protection** - Automatic retry with exponential backoff  
âœ… **Persistent Storage** - Local FAISS index for embeddings  

---

## ğŸ—ï¸ Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                          â”‚
â”‚              Streamlit Chat UI + File Upload                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DOCUMENT PROCESSING LAYER                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚   PDF       â”‚  â”‚    DOCX     â”‚  â”‚    TXT      â”‚            â”‚
â”‚  â”‚  Extractor  â”‚  â”‚  Extractor  â”‚  â”‚  Reader     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚                  â”‚  Text Combiner  â”‚                            â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TEXT CHUNKING LAYER                         â”‚
â”‚         RecursiveCharacterTextSplitter                          â”‚
â”‚         (chunk_size: 10000, overlap: 1000)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                EMBEDDING & VECTOR STORE LAYER                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  OpenAI Embeddings   â”‚ â”€â”€â”€â–º â”‚   FAISS Vector DB  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                  (Stored: faiss_index/)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUERY PROCESSING LAYER                       â”‚
â”‚  User Question â†’ Embedding â†’ Similarity Search â†’ Context        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LLM PROCESSING LAYER                       â”‚
â”‚              OpenAI ChatGPT (GPT-4/4-Turbo/3.5)                 â”‚
â”‚                  Context + Question â†’ Answer                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESPONSE GENERATION                          â”‚
â”‚            Streaming Output + Chat History Storage              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Diagram

1. **Document Upload Phase**:
   ```
   Upload Files â†’ Extract Text â†’ Combine â†’ Chunk â†’ Generate Embeddings â†’ Store in FAISS
   ```

2. **Query Phase**:
   ```
   User Question â†’ Embed Query â†’ Search FAISS â†’ Retrieve Context â†’ Generate Prompt â†’ LLM â†’ Response
   ```

### Component Breakdown

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **UI Framework** | Streamlit | Web interface and file upload |
| **Document Parsers** | PyPDF2, python-docx | Extract text from files |
| **Text Splitter** | LangChain RecursiveCharacterTextSplitter | Break text into chunks |
| **Embeddings** | OpenAI Embeddings API | Convert text to vectors |
| **Vector Store** | FAISS (Facebook AI Similarity Search) | Store and search embeddings |
| **LLM** | OpenAI GPT-4/4-Turbo/3.5-Turbo | Generate answers |
| **Orchestration** | LangChain | Chain components together |

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11 or higher
- OpenAI API Key
- Git

### Installation

1. **Clone the repository**
   ```bash
   git clone <your-repo-url>
   cd RAG_Gemini_BOT
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**
   
   Create a `.env` file in the project root:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```

### Running Locally

```bash
streamlit run rag.py
```

The application will open in your browser at `http://localhost:8501`

---

## ğŸ“– Usage Guide

### Step 1: Upload Documents
1. Click on the sidebar file uploader
2. Select one or multiple files (PDF, DOCX, or TXT)
3. Click "Submit & Process"
4. Wait for processing to complete

### Step 2: Select Model
Choose your preferred OpenAI model from the dropdown:
- **GPT-4**: Most capable, best for complex queries
- **GPT-4-Turbo**: Faster responses, good balance
- **GPT-3.5-Turbo**: Fastest, cost-effective

### Step 3: Ask Questions
Type your question in the chat input and press Enter. The bot will:
1. Search for relevant content in your uploaded documents
2. Generate a contextual answer using the selected GPT model
3. Display the response in the chat interface

### Step 4: Chat History
- All messages are stored in the session
- Use "Clear Chat History" button to reset

---

## ğŸ”§ Configuration

### Text Chunking Parameters

```python
chunk_size = 10000      # Characters per chunk
chunk_overlap = 1000    # Overlap between chunks
```

### Model Settings

```python
temperature = 0.3       # Lower = more focused, Higher = more creative
```

### Rate Limiting

```python
max_retries = 3         # Maximum retry attempts
retry_delay = 40        # Initial delay in seconds
                        # Exponential backoff: 40s â†’ 80s â†’ 160s
```

---

## ğŸ“‚ Project Structure

```
RAG_Gemini_BOT/
â”œâ”€â”€ rag.py                      # Main application file
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env                        # Environment variables (create this)
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml            # Streamlit configuration
â”œâ”€â”€ faiss_index/               # Vector store (auto-created)
â”‚   â””â”€â”€ index.faiss           # FAISS index file
â”œâ”€â”€ Architecture.drawio        # System architecture diagram
â”œâ”€â”€ dfd.drawio                # Data flow diagram
â””â”€â”€ README.md                  # This file
```

---

## ğŸ”‘ Key Functions

### Document Processing

- **`get_pdf_text(pdf_file)`**: Extract text from PDF files using PyPDF2
- **`get_word_text(docx_file)`**: Extract text from DOCX files
- **`read_text_file(txt_file)`**: Read text from TXT files
- **`combine_text(text_list)`**: Merge text from multiple files

### Text Processing

- **`get_text_chunks(text)`**: Split text into manageable chunks with overlap
- **`get_vector_store(chunks)`**: Generate embeddings and store in FAISS

### Query Processing

- **`user_input(user_question, modelname)`**: Process user queries and generate responses
- **`get_conversational_chain(modelname)`**: Initialize the OpenAI chat model

### UI Management

- **`clear_chat_history()`**: Reset chat session
- **`main()`**: Streamlit application entry point

---

## ğŸŒ Deployment

### Deploy to Streamlit Cloud

1. **Push to GitHub**
   ```bash
   git add .
   git commit -m "Initial commit"
   git push origin main
   ```

2. **Connect to Streamlit Cloud**
   - Go to [share.streamlit.io](https://share.streamlit.io)
   - Connect your GitHub repository
   - Select `rag.py` as the main file

3. **Add Secrets**
   In Streamlit Cloud dashboard â†’ App Settings â†’ Secrets:
   ```toml
   OPENAI_API_KEY = "your_api_key_here"
   ```

4. **Deploy**
   Click "Deploy" and wait for the app to start

---

## ğŸ› ï¸ Technologies Used

| Technology | Version | Purpose |
|------------|---------|---------|
| **Python** | 3.11+ | Programming language |
| **Streamlit** | Latest | Web framework |
| **LangChain** | Latest | LLM orchestration |
| **OpenAI** | Latest | GPT models API |
| **FAISS** | 1.7.4+ | Vector similarity search |
| **PyPDF2** | 3.0.0+ | PDF text extraction |
| **python-docx** | 1.0.0+ | DOCX text extraction |

---

## âš ï¸ Error Handling

The application includes robust error handling:

- **Rate Limiting**: Automatic detection and retry with exponential backoff
- **API Errors**: Graceful error messages for quota/connection issues
- **File Processing**: Validation and error reporting for corrupt files
- **Session Management**: Proper state management to prevent crashes

---

## ğŸ“Š Performance Considerations

- **Chunk Size**: Larger chunks provide more context but slower processing
- **Overlap**: Ensures context continuity across chunk boundaries
- **Model Selection**: Balance between quality (GPT-4) and speed/cost (GPT-3.5)
- **FAISS Index**: Stored locally for fast retrieval after initial processing

---

## ğŸ”’ Security Notes

- âš ï¸ Never commit `.env` file to version control
- âš ï¸ Use Streamlit Cloud secrets for deployment
- âš ï¸ Keep your OpenAI API key secure
- âš ï¸ Set appropriate usage limits on your OpenAI account

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: `ModuleNotFoundError`
- **Solution**: Ensure all dependencies are installed: `pip install -r requirements.txt`

**Issue**: `OpenAI API Key Error`
- **Solution**: Check `.env` file exists and contains valid API key

**Issue**: `Rate Limit Exceeded`
- **Solution**: Wait for retry or upgrade OpenAI plan

**Issue**: `FAISS Index Not Found`
- **Solution**: Upload and process documents first before asking questions

---

## ğŸ“ Future Enhancements

- [ ] Support for additional file formats (CSV, Excel, Images with OCR)
- [ ] Multi-language support
- [ ] Document source citations in responses
- [ ] Advanced filtering and search options
- [ ] User authentication and document management
- [ ] Integration with other LLM providers (Anthropic, Google)
- [ ] Agentic RAG capabilities with tool usage

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Design & Developed by Code Insights @pramodklal**

---

## ğŸ“ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Contact: [Your contact information]

---

## ğŸ™ Acknowledgments

- OpenAI for GPT models
- LangChain for the orchestration framework
- Facebook AI for FAISS
- Streamlit for the amazing web framework
- The open-source community

---

**Built with â¤ï¸ for the AI community**

